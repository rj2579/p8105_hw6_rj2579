---
title: "homework 6"
output: github_document
---

```{r}
library(tidyverse)
library(modelr)
library(mgcv)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = 0.6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.color = "viridis",
  ggplot2.continuous.fill = "viridis"
)

sclae_color_discrete = scale_color_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

## Problem 1 is a lecture example 

## Problem 2

##### import and clean data 
```{r}
birth_wt = read_csv("./data/birthweight.csv") %>% 
  janitor::clean_names() %>% 
   mutate(
     babysex = as.factor(babysex),
     frace = as.factor(frace),
     malform = as.factor(malform),
     mrace = as.factor(mrace),
     babysex = recode(babysex,"1"="male","2"="female"),
     frace = recode(frace,"1" = "White", "2" = "Black", "3" = "Asian", "4" = "Puerto Rican", "8" = "Other", "9" = "Unknown"),
     malform = recode(malform,"0" = "absent", "1" = "present"),
     mrace = recode(mrace,"1" = "White", "2" = "Black", "3" = "Asian", "4" = "Puerto Rican", "8" = "Other")
     )
```


##### propose a regression model for brthweight 
```{r}
# first step: fit a model with all the variables 
full_model = lm(bwt ~ ., data = birth_wt)
# perform a backward step-wise elimination 
step(full_model,direction = "backward") 
# according to the output of the backward elimination, the following model has the smallest AIC, so below is my final model for birthweight 
current_model = lm(formula = bwt ~ babysex + bhead + blength + delwt + fincome + 
    gaweeks + mheight + mrace + parity + ppwt + smoken, data = birth_wt)
```

I first fitted a full model that contains all variables. This model can be used for comparison later one. 
Then, I used the backward function to perform a step-wise subtraction to eliminate variables that are not significantly associated with our outcome of interest, baby's birth weight. According to the function output, variable babysex,  bhead, blength, delwt, fincome, gaweeks, mheight, mrace, parity, ppwt, and smoken should be included into the model. And such model fit our dataset the best. 


##### plot of model residuals against fitted values
```{r}
residuals = add_residuals(birth_wt, current_model)
predictions = add_predictions(birth_wt, current_model)
resid_pred = merge(residuals,predictions)

resid_pred %>% 
  ggplot(aes(x = pred, y = resid, color = bwt)) +
  geom_point(alpha = 0.5) +
  geom_hline(aes(yintercept = 0), color = "red") +
  labs(
    title = "Model residuals against fitted values",
    x = "Predictions",
    y = "Residuals"
  )
```

The residuals are more concentrated near 0 when the predicted values are larger. When the predicted values are smaller, residuals tend to be a little bit spread out. 

##### compare your model to two others
```{r}
given_model1 = lm(bwt ~ blength + gaweeks, data = birth_wt)
given_model2 = lm(bwt ~ bhead + blength + babysex + bhead*blength + bhead*babysex + blength*babysex + bhead*blength*babysex, data = birth_wt)
```

```{r}
cv_df =
  crossv_mc(birth_wt, 100) %>% 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble))

cv_df = 
  cv_df %>% 
  mutate(
    current_model = map(train, ~lm(
                                   formula = bwt ~ babysex + bhead + blength + delwt + fincome + 
                                   gaweeks + mheight + mrace + parity + ppwt + smoken, data = birth_wt
                                   )),
    given_model1 = map(train, ~lm(
                                  bwt ~ blength + gaweeks, data = birth_wt
                                  )),
    given_model2 = map(train, ~lm(
                                  bwt ~ bhead + blength + babysex + bhead*blength + bhead*babysex +
                                  blength*babysex + bhead*blength*babysex, data = birth_wt
                                  ))
    ) %>% 
  mutate(
    rmse_current = map2_dbl(current_model, test, ~rmse(model = .x, data = .y)),
    rmse_model1 = map2_dbl(given_model1, test, ~rmse(model = .x, data = .y)),
    rmse_model2 = map2_dbl(given_model2, test, ~rmse(model = .x, data = .y)))
```

```{r}
cv_df %>%
  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(),
    names_to = "model",
    values_to = "rmse",
    names_prefix = "rmse_") %>% 
  mutate(model = fct_inorder(model)) %>%
  ggplot(aes(x = model, y = rmse)) +
  geom_violin(aes(fill = model)) + 
  theme_light()
```


## Problem 3 

##### import data 
```{r}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())
```

##### produce estimated of the two quantities 
```{r}
boot_straps = 
  weather_df %>% 
  modelr::bootstrap(n = 5000) %>% 
  mutate(
    models = map(strap, ~ lm(tmax ~ tmin, data = .x)),
    r_square = map(models, broom::glance),
    results = map(models, broom::tidy)
    ) %>% 
  select(-strap, -models) %>% 
  #obtain the estimated r-squares
  unnest(r_square, results) %>% 
  janitor::clean_names() 


beta_df = 
  boot_straps %>% 
  mutate(term = recode(term, "(Intercept)" = "intercept")) %>% 
  #obtain the estimated betas 
  pivot_wider(
    id_cols = id,
    names_from = term,
    values_from = estimate
  ) %>% 
  mutate(log_betas = log(intercept * tmin))
```

##### plot the distribution of the r-square and log(beta0*beta1)
```{r, error = TRUE}
#plot the distribution of the r-square
boot_straps %>% 
  filter(term == "tmin") %>% 
  ggplot(aes(x = r_squared)) + 
  geom_density() +
  geom_vline(aes(xintercept = mean(r_squared))) +
  labs(
    title = "The distribution of estimated r-square"
  ) 


#plot the distribution of the log(beta0*beta1)
beta_df %>% 
  ggplot(aes(x = log_betas)) + 
  geom_density() +
  geom_vline(aes(xintercept = mean(log_betas))) +
  labs(
    title = "The distribution of estimated log(beta0*beta1)"
  )

```


##### identify the 2.5% and 97.5% quantiles to provide a 95% confidence interval for r-square and log(beta0*beta1)
```{r}
#95% confidence interval for r-square
boot_straps %>% 
  filter(term == "tmin") %>% 
  pull(r_squared) %>% 
  quantile(c(0.025, 0.975)) %>% 
  broom::tidy() %>% 
  knitr::kable(digits = 4,
               caption = "The 95% confidence interval for r-square")


# 95% confidence interval for log(beta0*beta1)
beta_df %>% 
  pull(log_betas) %>% 
  quantile(c(0.025, 0.975)) %>% 
  broom::tidy() %>% 
  knitr::kable(digits = 4,
               caption = "The 95% confidence interval for log(beta0*beta1)")
```

